{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38.58364406 34.34619544 30.89081294 27.93062051 24.88376953 22.56866088\n",
      " 20.32152618 18.40247108 16.58534059 14.93300112 13.45546167 12.0911392\n",
      " 10.9263694   9.79104276  8.8826086   7.98419025  7.24687719  6.52717597\n",
      "  5.90523652  5.34885142  4.82116115  4.3672633   3.93922941  3.56590957\n",
      "  3.22634632  2.90428847  2.61309852  2.360745    2.13125294  1.91731805\n",
      "  1.73044488  1.56680519  1.40688944  1.27684599  1.15307048  1.03913648\n",
      "  0.93854756  0.84082882  0.75982894  0.68934112  0.62506331  0.55842443\n",
      "  0.50028669  0.45083977  0.40380504  0.36174708  0.32585859  0.2893414\n",
      "  0.26002066  0.23279599]\n"
     ]
    }
   ],
   "source": [
    "X = np.random.normal(0,1,(1000,50))\n",
    "import numpy.linalg as lin\n",
    "\n",
    "# the following is to make X more skewed towards a low rank matrix, so the results\n",
    "# are more instructive. \n",
    "u,l,v = lin.svd(X)\n",
    "wt = [1.1**(-x) for x in range(len(l))]\n",
    "l = l * wt\n",
    "print(l)\n",
    "\n",
    "X = u @ np.vstack((np.diag(l),np.zeros((950,50)))) @ v.T\n",
    "\n",
    "# m is the number of coordinates of the input examples, 10 is the \n",
    "# number of latent coordinates we will use to reconstruct the data\n",
    "m = 50\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 0s 936us/step - loss: 0.1739\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 0s 694us/step - loss: 0.1335\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 0s 848us/step - loss: 0.1081\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 0s 701us/step - loss: 0.0887\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 0s 862us/step - loss: 0.0736\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 0s 734us/step - loss: 0.0622\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 0s 968us/step - loss: 0.0537\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 0s 784us/step - loss: 0.0475\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0427\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0389\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0357\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.0330\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0305\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 0s 866us/step - loss: 0.0284\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 0s 985us/step - loss: 0.0267\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 0s 789us/step - loss: 0.0253\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0243\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0234\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 0s 850us/step - loss: 0.0227\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22988927d60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder = models.Sequential()\n",
    "Wlayer = layers.Dense(k,activation='linear', input_shape=(m,))\n",
    "autoencoder.add(Wlayer)\n",
    "\n",
    "Vlayer = layers.Dense(m,activation='linear')\n",
    "# If you want to fix V and see how W varies, uncomment the following line:\n",
    "# Vlayer.trainable = False\n",
    "autoencoder.add(Vlayer)\n",
    "\n",
    "#Vlayer.set_weights([V.T,np.zeros(50,)])\n",
    "autoencoder.compile(optimizer='rmsprop', loss='mse')\n",
    "autoencoder.fit(X,X,epochs=20,batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0217\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 0s 551us/step - loss: 0.0214\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 0s 858us/step - loss: 0.0211\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 0s 696us/step - loss: 0.0208\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 0s 924us/step - loss: 0.0206\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 0s 833us/step - loss: 0.0204\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 0s 751us/step - loss: 0.0203\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 0s 759us/step - loss: 0.0202\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0201\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0199\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0199\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 0s 830us/step - loss: 0.0198\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0198\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0198\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0197\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0197\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0197\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0197\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2298900d610>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X,X,epochs=20,batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of W:  (10, 50)\n",
      "shape of V:  (50, 10)\n"
     ]
    }
   ],
   "source": [
    "W = autoencoder.layers[0].get_weights()[0].T\n",
    "V = autoencoder.layers[1].get_weights()[0].T\n",
    "print('shape of W: ', W.shape)\n",
    "print('shape of V: ', V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0., -0., -0., -0.,  0.,  0.,  0., -0., -0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0., -0., -0.,  0., -0., -0.],\n",
       "       [-0., -0.,  1., -0., -0., -0., -0., -0., -0.,  0.],\n",
       "       [-0.,  0., -0.,  1.,  0.,  0.,  0., -0.,  0., -0.],\n",
       "       [ 0.,  0., -0., -0.,  1., -0.,  0.,  0.,  0., -0.],\n",
       "       [-0., -0., -0.,  0., -0.,  1., -0.,  0., -0., -0.],\n",
       "       [ 0.,  0., -0., -0., -0.,  0.,  1., -0., -0., -0.],\n",
       "       [ 0., -0., -0.,  0., -0.,  0.,  0.,  1.,  0., -0.],\n",
       "       [-0., -0.,  0., -0., -0., -0., -0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0., -0., -0., -0.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that WV =I, the weights W of the first \n",
    "# layer is the projection into the column space of the weights of the second layer, V.\n",
    "# You won't get exactly I because the optimization is stochastic, but close enough\n",
    "\n",
    "np.round(W @ V,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2, -0.1, -0.1, ...,  0.1,  0. , -0. ],\n",
       "       [-0. ,  0.2,  0.1, ...,  0. ,  0. ,  0. ],\n",
       "       [-0.1,  0.1,  0.1, ..., -0. , -0. ,  0.1],\n",
       "       ...,\n",
       "       [ 0. , -0.1, -0. , ...,  0.4,  0. ,  0.1],\n",
       "       [ 0. ,  0. , -0. , ..., -0.1,  0.1, -0.1],\n",
       "       [-0. ,  0. ,  0.1, ...,  0.1, -0. ,  0.2]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(V @ W, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We build a new model that ties the weights of the W and V layers (ie forces W=V^T) \n",
    "# to force the weight matrices V (W resp) of the prior example to have orthogonal \n",
    "# columns, ie V^T V = I (rows resp, W W^T = I) \n",
    "\n",
    "# This approximates the SVD. To tie the weights together, we will have to \n",
    "# extend the keras.layers.Layer class to take in another layer, and use the weights from \n",
    "# that layer. The minimal thing we need to do for this is redefine the output computation \n",
    "# when the layer is called, and this is achieved by redefining the inbuilt call function of \n",
    "# the Layer class. \n",
    "\n",
    "class mylayer(layers.Layer):\n",
    "    def __init__(self, tracklayer=None, activation=None, **kwargs):\n",
    "        self.kernel_to_track = tracklayer\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        output = tf.matmul(inputs, self.kernel_to_track.weights[0], transpose_b = True)\n",
    "        return self.activation(output)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To define the autoencoder model:\n",
    "\n",
    "class autoencoder_svd(keras.Model):\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = layers.Dense(10, activation = 'linear')\n",
    "        self.decoder = mylayer(self.encoder, activation = 'linear')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        w = self.encoder(inputs)\n",
    "        self.latent = w\n",
    "        hatx = self.decoder(w)\n",
    "        return(hatx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method mylayer.call of <__main__.mylayer object at 0x0000022989569CA0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method mylayer.call of <__main__.mylayer object at 0x0000022989569CA0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32/32 [==============================] - 0s 896us/step - loss: 0.1416\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 0s 667us/step - loss: 0.1185\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 0s 814us/step - loss: 0.1022\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 0s 691us/step - loss: 0.0880\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 0s 536us/step - loss: 0.0764\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 0s 705us/step - loss: 0.0672\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 0s 971us/step - loss: 0.0594\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 0s 861us/step - loss: 0.0529\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0477\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0438\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0408\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 0s 969us/step - loss: 0.0385\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0365\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 0s 945us/step - loss: 0.0346\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 0s 817us/step - loss: 0.0328\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 0s 904us/step - loss: 0.0312\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 0s 782us/step - loss: 0.0298\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 0s 781us/step - loss: 0.0287\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0277\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 0s 769us/step - loss: 0.0269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x229895a8e20>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svdnn = autoencoder_svd()\n",
    "\n",
    "svdnn.compile(optimizer='adam', loss='mse')\n",
    "svdnn.fit(X,X,epochs=20,batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.0262\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 0s 806us/step - loss: 0.0255\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 0s 682us/step - loss: 0.0249\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0243\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 0s 882us/step - loss: 0.0237\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 0s 676us/step - loss: 0.0232\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0227\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 0s 875us/step - loss: 0.0222\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 0s 683us/step - loss: 0.0218\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 0s 691us/step - loss: 0.0215\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 0s 873us/step - loss: 0.0212\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 0s 675us/step - loss: 0.0209\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 0s 717us/step - loss: 0.0207\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0205\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0203\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.018 - 0s 744us/step - loss: 0.0201\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0200\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0199\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2298f334c40>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svdnn.fit(X,X,epochs=20,batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0., -0., -0.,  0.,  0.,  0., -0.,  0., -0.],\n",
       "       [ 0.,  1.,  0.,  0., -0.,  0., -0.,  0.,  0.,  0.],\n",
       "       [-0.,  0.,  1., -0.,  0.,  0., -0., -0.,  0., -0.],\n",
       "       [-0.,  0., -0.,  1.,  0., -0., -0.,  0., -0., -0.],\n",
       "       [ 0., -0.,  0.,  0.,  1., -0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., -0., -0.,  1.,  0.,  0., -0., -0.],\n",
       "       [ 0., -0., -0., -0.,  0.,  0.,  1.,  0.,  0., -0.],\n",
       "       [-0.,  0., -0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., -0.,  0., -0.,  0.,  0.,  1.,  0.],\n",
       "       [-0.,  0., -0., -0.,  0., -0., -0.,  0.,  0.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = svdnn.encoder.weights[0].numpy() \n",
    "print(W.shape)\n",
    "\n",
    "np.round(W.T @W,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 10)\n",
      "[0.95233522 0.99358056 0.95987988 0.9969597  0.9835332  0.99383293\n",
      " 0.99459085 0.96955484 0.98650035 0.99621449]\n"
     ]
    }
   ],
   "source": [
    "# finally, we check how much power the columns of W carry on the top 10 eigen-vectors\n",
    "# of X^TX, ie the best directions to represent the rows of X.\n",
    "# The closer these numbers are to 1, the better the column space of W represents the \n",
    "# optimal linear space to project the rows of X into. Not all numbers need to be \n",
    "# close to 1, but at least some need to be.\n",
    "\n",
    "V = v[:,0:10]\n",
    "print(V.shape)\n",
    "\n",
    "\n",
    "# This is the projection of W into smaller eigen-directions\n",
    "pwr = lin.inv(V.T @ V) @ V.T @ W\n",
    "\n",
    "print(np.diag(pwr.T @ pwr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
