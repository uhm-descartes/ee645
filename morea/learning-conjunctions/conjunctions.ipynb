{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> EE 445 Spring 2023</h3>\n",
    "<h3> PAC Learnability</h3>\n",
    "<h4> Narayana Santhanam </h4>\n",
    "\n",
    "\n",
    "\n",
    "This notebook is a demonstration of the PAC learning example we went over in the first week of classes. You will learn more about PAC learnability in EE645, but you should get a feel for modeling probabilistically. You should get comfortable with thinking about discrete probability with this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated conjunction:   ~x(3) AND ~x(4)\n"
     ]
    }
   ],
   "source": [
    "n = 15\n",
    "\n",
    "# A conjunction on n variables is represented as a ternary vector of length n. \n",
    "# 1 in the ith position indicates x(i) exists in the conjunction.\n",
    "# 0 in the jth position indicates ~x(j) exists in the conjunction.\n",
    "# 2 in the kth position indicates both x(k) and ~x(k) are absent in the conjunction.\n",
    "# Numbering of variables is from 0. \n",
    "# For example if n =3 and the conjunction is x(1), we use the vector [2,1,2]. \n",
    "# If the conjunction is x(0) AND ~x(2), we use the vector [1,2,0] to represent it.\n",
    "def humanreadable(c):\n",
    "    # Translates the representation of the conjunction to an easily readable form.\n",
    "    if len(c)==0:\n",
    "        return '0'\n",
    "    literals = [x for x in range(n) if c[x] !=2 ]\n",
    "    conj = ''\n",
    "    for i in literals:\n",
    "        if c[i] == 1:\n",
    "            conj+=' x('+str(i)+') AND'\n",
    "        else:\n",
    "            conj+=' ~x('+str(i)+') AND'\n",
    "    if conj == '':\n",
    "        return '1'\n",
    "    else:\n",
    "        return conj[:-len(' AND')]\n",
    "\n",
    "def concept():\n",
    "    # Generates a random concept\n",
    "    c = npr.choice([0,1,2], size = (n,), p = [.03,.03,.94])\n",
    "    print('Generated conjunction: ', humanreadable(c))\n",
    "    return c\n",
    "\n",
    "c = concept()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training vectors: \n",
      " [[0 0 0 ... 0 1 1]\n",
      " [1 0 1 ... 1 0 1]\n",
      " [1 0 0 ... 0 1 0]\n",
      " ...\n",
      " [1 1 0 ... 0 1 0]\n",
      " [1 1 1 ... 1 0 0]\n",
      " [1 1 0 ... 0 1 1]]\n",
      "labels [0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0.\n",
      " 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "def evaluate(c, z):\n",
    "    # evaluate a concept c on the given m training vectors arranged in a matrix z.  \n",
    "    # each row of z is a separate training vector, so z has shape m x n\n",
    "    m = z.shape[0]\n",
    "    if len(c) == 0:\n",
    "        return np.zeros((m,))\n",
    "    discrepancies = [ y for y in range(m) for x in range(n) if z[y,x] != c[x] and c[x] !=2 ]\n",
    "    labels = np.ones((m,))\n",
    "    labels[list(set(discrepancies))] = 0\n",
    "    return labels\n",
    "\n",
    "def generateone(m, c):\n",
    "    # Generate m examples from a distribution D_1. m needs to be a multiple of 5.\n",
    "    # Assignment: can you describe what this distribution is?\n",
    "    z = np.tile(npr.choice([0,1], size = (m,5)), int(n/5))\n",
    "    labels = evaluate(c,z)\n",
    "    return z, labels\n",
    "    \n",
    "m = 100\n",
    "z, labels = generateone(m, c)\n",
    "print('Training vectors: \\n', z)\n",
    "print('labels', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated concept:  ~x(3) AND ~x(4) AND ~x(8) AND ~x(9) AND ~x(13) AND ~x(14)\n",
      "True concept:       ~x(3) AND ~x(4)\n"
     ]
    }
   ],
   "source": [
    "# Algorithm to infer the conjunction from training vectors z and their labels. \n",
    "# This ignores all training vectors whose label is 0. \n",
    "# If there is a training vector with label 1, it discards all literals inconsistent with the example.\n",
    "# If no label is one, estimate concept is [], which evaluates to 0 everywhere\n",
    "# Verify the output hatc is always consistent with the examples it is trained on.\n",
    "hatc = []\n",
    "for i in range(m):\n",
    "    if labels[i] == 1:\n",
    "        hatc = z[i,:]\n",
    "        break\n",
    "        \n",
    "for i in range(m):\n",
    "    if labels[i] == 1:\n",
    "        discard = np.where(hatc != z[i,:])\n",
    "        hatc[discard] = 2\n",
    "        \n",
    "print('Estimated concept:', humanreadable(hatc))\n",
    "print('True concept:     ', humanreadable(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you test it on samples generated by the training distribution:\n",
    "ztest, truelabels = generateone(10000,c)\n",
    "\n",
    "estimatedlabels = evaluate(hatc, ztest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalization accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# all is well\n",
    "gen_acc = np.size(np.where(truelabels == estimatedlabels))/10000\n",
    "print(\"Generalization accuracy:\", gen_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of distribution accuracy: 0.1919\n"
     ]
    }
   ],
   "source": [
    "# But if we use a different distribution? \n",
    "# You can almost always generate a distribution below that yields high error probability.\n",
    "\n",
    "def generatetwo(m,c):\n",
    "    # Can you modify this distribution so as to give a high error probability for the hatc you \n",
    "    # obtained in the previous cells?\n",
    "    z = npr.choice([0,1], size = (m,n), p = [0.9,0.1])    \n",
    "    z[:,8] = 1\n",
    "    z[:,9] = 1\n",
    "    labels = evaluate(c,z)\n",
    "    return z, labels\n",
    "\n",
    "ztest, trueoodlabels = generatetwo(10000,c)\n",
    "estimatedoodlabels = evaluate(hatc, ztest)\n",
    "ood_acc = np.size(np.where(trueoodlabels == estimatedoodlabels))/10000\n",
    "print('Out of distribution accuracy:', ood_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
